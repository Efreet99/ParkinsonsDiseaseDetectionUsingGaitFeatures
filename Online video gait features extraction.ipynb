{"cells":[{"cell_type":"code","source":["# Run in desktop"],"metadata":{"id":"NSekf5fitFXA"},"id":"NSekf5fitFXA","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"65b3d829","metadata":{"id":"65b3d829"},"outputs":[],"source":["import os\n","import json\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import math\n","import sys\n","import cv2\n","import tqdm\n","import seaborn as sns\n","from scipy import signal\n","from jupyterthemes import jtplot\n","\n","jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"id":"d637584e","metadata":{"id":"d637584e"},"outputs":[],"source":["# Define the path to the dataset\n","DATASET_PATH = r'C:\\Users\\User\\Desktop\\FYP2\\Alphapose_results'\n","\n","# Dictionary that maps body keypoints to their respective indices \n","# refer to -> https://github.com/Fang-Haoshu/Halpe-FullBody\n","keypoints_code = {\"Nose\" : 0, \"LShoulder\" : 5,  \"RShoulder\" : 6, \"LElbow\" : 7, \"RElbow\" : 8, \"LWrist\" : 9, \n","                  \"RWrist\" : 10,\"LHip\" : 11, \"RHip\" : 12, \"LKnee\" : 13, \"RKnee\" : 14,\"LAnkle\" : 15,\n","                  \"RAnkle\" : 16, \"Head\" : 17, \"Neck\" : 18, \"Hip\" : 19, \"LBigToe\" : 20, \"RBigToe\" : 21, \"LSmallToe\" : 22,\n","                  \"RSmallToe\" : 23, \"LHeel\" : 24, \"RHeel\" : 25}\n","\n","# Convert dict key to list\n","keypoints_list = list(keypoints_code.keys())"]},{"cell_type":"markdown","id":"c12125ff","metadata":{"id":"c12125ff"},"source":["## Reading data"]},{"cell_type":"code","execution_count":null,"id":"8e11c79b","metadata":{"id":"8e11c79b"},"outputs":[],"source":["def read_data(*CLASSES_NAME):\n","    all_x, all_y, videos_path, frames= [], [], [], []\n","    for CLASS_NAME in CLASSES_NAME:\n","        print('Reading data of class %s...' % CLASS_NAME)\n","        # Get into class folder\n","        files = os.listdir(os.path.join(DATASET_PATH, CLASS_NAME))\n","        with tqdm.tqdm(total=len(files), ascii=' >=', file=sys.stdout) as pbar:\n","            for file in files:\n","                json_path = os.path.join(DATASET_PATH, CLASS_NAME, file, 'alphapose-results.json')\n","                video_path = os.path.join(DATASET_PATH, CLASS_NAME, file, f'AlphaPose_{file}')\n","                f = open(json_path)\n","                all_data = json.load(f)\n","                f.close()\n","                x, y, frame = [], [], []\n","                previous_frame = '' # Variable that stores the image ID of the previous frame\n","                previous_score = 0 # Variable that stores the score of the previous frame\n","                for data in all_data:\n","                    # Extract the image ID and score for the current frame\n","                    current_frame = data['image_id']\n","                    current_score = data['score']\n","                    \n","                    # Check if the current frame is the same as the previous frame\n","                    if current_frame == previous_frame:\n","                        # If the current score is higher than the previous score,\n","                        # remove the last data\n","                        if current_score > previous_score:\n","                            x.pop()\n","                            y.pop()\n","                        else:\n","                            # If the current score is not higher, skip processing\n","                            continue\n","                    else:\n","                        frame.append(current_frame.split('.')[0])\n","                    # Set current frame as previous frame\n","                    previous_frame = current_frame\n","                    previous_score = current_score\n","                    keypoints = data['keypoints']\n","                    filtered_x, filtered_y = [], []\n","                    # Read only the keypoints we want\n","                    for keypoint_code in keypoints_code.values():\n","                        filtered_x.append(keypoints[keypoint_code*3])\n","                        filtered_y.append(keypoints[keypoint_code*3+1])\n","                    x.append(filtered_x)\n","                    y.append(filtered_y)\n","                all_x.append(x)\n","                all_y.append(y)\n","                frames.append(frame)\n","                videos_path.append(video_path)\n","                pbar.update(1)\n","    return all_x, all_y, videos_path, frames"]},{"cell_type":"code","execution_count":null,"id":"1b6dc53e","metadata":{"id":"1b6dc53e","outputId":"cd83e7db-1292-400e-c43d-5e349c8e464b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading data of class SEVERE...\n","100%|==================================================================================| 52/52 [00:07<00:00,  7.07it/s]\n","Reading data of class MODERATE...\n","100%|==================================================================================| 61/61 [00:06<00:00,  8.83it/s]\n","Reading data of class MILD...\n","100%|==================================================================================| 29/29 [00:02<00:00, 11.84it/s]\n","Reading data of class NORMAL...\n","100%|================================================================================| 150/150 [00:09<00:00, 15.86it/s]\n"]}],"source":["all_x_pd, all_y_pd, videos_path_pd, detected_frames_pd = read_data('SEVERE', 'MODERATE', 'MILD')\n","all_x_normal, all_y_normal, videos_path_normal, detected_frames_normal = read_data('NORMAL')"]},{"cell_type":"markdown","id":"415c106e","metadata":{"id":"415c106e"},"source":["## Gait features extraction"]},{"cell_type":"markdown","id":"59cdc9c2","metadata":{"id":"59cdc9c2"},"source":["### Stride segmentation"]},{"cell_type":"code","execution_count":null,"id":"520efb12","metadata":{"id":"520efb12"},"outputs":[],"source":["## All extraction functions are writen in batch mode\n","\n","# low pass filter to reduce frequency of points\n","def butter_lowpass(cutoff, fs, order=5):\n","    return signal.butter(order, cutoff, fs=fs, btype='lowpass', analog=False)\n","\n","def butter_lowpass_filter(data, cutoff, fs, order=5):\n","    b, a = butter_lowpass(cutoff, fs, order=order)\n","    y = signal.filtfilt(b, a, data)\n","    return y\n","    "]},{"cell_type":"code","execution_count":null,"id":"fcf2426f","metadata":{"id":"fcf2426f"},"outputs":[],"source":["def stride_segmentation(all_y, videos_path=None, graph=False):\n","    total_person = len(all_y)\n","    all_peaks = []\n","    # For display graph purpose\n","    if graph:\n","        cols = 2\n","        rows = int(math.ceil((total_person/4)/cols))\n","        fig = plt.figure(layout='constrained', figsize=[6.4*cols*2, 4.8*rows+4])\n","        subfigs = fig.subfigures(rows, cols, hspace=0.07, wspace=0.07)\n","        j=0\n","    for i in range(total_person):\n","        # Get the y-coordinate of heel and apply low pass\n","        y1 = [frame[keypoints_list.index('RHeel')] for frame in all_y[i]]\n","        y1 = butter_lowpass_filter(y1, 5, 24)\n","        y2 = [frame[keypoints_list.index('LHeel')] for frame in all_y[i]]\n","        y2 = butter_lowpass_filter(y2, 5, 24)\n","        \n","        # Get local minimal\n","        peaks_right, _ = signal.find_peaks([p for p in y1], distance = 24)\n","        peaks_left, _ = signal.find_peaks([p for p in y2], distance = 24)\n","        all_peaks.append([peaks_right,peaks_left])\n","        \n","        # For display graph\n","        if graph:\n","            if i % 4 == 0:\n","                subfigs[int(j/2),j%2].suptitle('_'.join(videos_path[i].split('\\\\')[-1].split('.')[0].split('_')[1:]) + f'\\ni = {i}', fontsize = 20)\n","                axs = subfigs[int(j/2),j%2].subplots(1, 2)\n","                x1 = list(range(0,len(y1)))\n","                axs[0].plot(x1, y1)\n","                axs[0].scatter([x1[peak] for peak in peaks_right], [y1[peak] for peak in peaks_right], \n","                               marker = 'X', color='red', label='Stride (n): %d' % int(peaks_right.shape[0]-1))\n","                axs[0].invert_yaxis()\n","                axs[0].set_title('Right Stride')\n","                axs[0].legend()\n","\n","                x2 = list(range(0,len(y2)))\n","                axs[1].plot(x2, y2, color='green')\n","                axs[1].scatter([x2[peak] for peak in peaks_left], [y2[peak] for peak in peaks_left], \n","                               marker = 'X', color='red', label='Stride (n): %d' % int(peaks_left.shape[0]-1))\n","                axs[1].invert_yaxis()\n","                axs[1].set_title('Left Stride')\n","                axs[1].legend()\n","                j += 1\n","    if graph:\n","        plt.show()        \n","    return all_peaks"]},{"cell_type":"code","execution_count":null,"id":"7e7be570","metadata":{"id":"7e7be570"},"outputs":[],"source":["all_peaks_pd = stride_segmentation(all_y_pd, videos_path=videos_path_pd)\n","all_peaks_normal = stride_segmentation(all_y_normal, videos_path=videos_path_normal)"]},{"cell_type":"markdown","id":"7908d9b4","metadata":{"id":"7908d9b4"},"source":["### Stride ratio"]},{"cell_type":"code","execution_count":null,"id":"9a2bca37","metadata":{"id":"9a2bca37"},"outputs":[],"source":["def mean(lst):\n","    return sum(lst)/len(lst)\n","\n","def get_x_ratio(all_x, all_y, peaks):\n","    # Get x-coordinate of detected strides\n","    xR = [[all_x[i][peak][keypoints_list.index('RHeel')] for peak in peaks[i][0]] for i in range(len(all_x))]\n","    xL = [[all_x[i][peak][keypoints_list.index('LHeel')] for peak in peaks[i][1]] for i in range(len(all_x))]\n","    \n","    # Get x-coordinate of nose and hip\n","    yN = [[frame[keypoints_list.index('Nose')] for frame in person] for person in all_y]\n","    yH = [[frame[keypoints_list.index('Hip')] for frame in person] for person in all_y]\n","    \n","    # Calculate the distance in pixels of x-coord of detected strides\n","    diffsR = [[abs(j-i) for i, j in zip(x[:-1], x[1:])] for x in xR]\n","    diffsL = [[abs(j-i) for i, j in zip(x[:-1], x[1:])] for x in xL]\n","    \n","    # Calculate the mean of nose to hip distance\n","    nth = [mean([abs(y1-y2) for y1,y2 in zip(yN[i], yH[i])]) for i in range(len(all_y))]\n","    \n","     # Calculate the mena of ratio between the distance of detected strides and the nose to hip distance\n","    ratioR = [mean(diff)/nth_dist for diff, nth_dist in zip(diffsR, nth)]\n","    ratioL = [mean(diff)/nth_dist for diff, nth_dist in zip(diffsR, nth)]\n","    return ratioR, ratioL\n","    \n","ratioR_pd, ratioL_pd = get_x_ratio(all_x_pd, all_y_pd, all_peaks_pd)\n","ratioR_normal, ratioL_normal = get_x_ratio(all_x_normal, all_y_normal, all_peaks_normal)"]},{"cell_type":"code","execution_count":null,"id":"02fc797d","metadata":{"id":"02fc797d"},"outputs":[],"source":["def get_y_ratio(x, y, peaks):\n","    # Apply same method with get_x_ratio\n","    # Only difference is to get y-coord of Heel\n","    yR = [y[peak][keypoints_list.index('RHeel')] for peak in peaks[0]]\n","    yL = [y[peak][keypoints_list.index('LHeel')] for peak in peaks[1]]\n","    yN = [frame[keypoints_list.index('Nose')] for frame in y]\n","    yH = [frame[keypoints_list.index('Hip')] for frame in y]\n","    diffsR = [abs(j-i) for i, j in zip(yR[:-1], yR[1:])]\n","    diffsL = [abs(j-i) for i, j in zip(yL[:-1], yL[1:])]\n","    nth = mean([abs(y1-y2) for y1,y2 in zip(yN, yH)])\n","    ratioR = mean(diffsR)/nth\n","    ratioL = mean(diffsL)/nth\n","    return ratioR, ratioL"]},{"cell_type":"code","execution_count":null,"id":"32c8701e","metadata":{"id":"32c8701e"},"outputs":[],"source":["# If the right stride ratio of a normal person is less than the\n","# mean of the right stride ratios of PD patients\n","# try apply get_y_ratio\n","pd_mean = mean(ratioR_pd)\n","for i,ratio in enumerate(ratioR_normal):\n","    if ratio < pd_mean:\n","        ratioR, ratioL = get_y_ratio(all_x_normal[i], all_y_normal[i], all_peaks_normal[i])\n","        # Only replace the original ratio if result of get_y_ratio > original ratio\n","        if ratioR > ratio:\n","            ratioR_normal[i] = ratioR\n","            ratioL_normal[i] = ratioL"]},{"cell_type":"markdown","id":"c5af923f","metadata":{"id":"c5af923f"},"source":["### Cadence"]},{"cell_type":"code","execution_count":null,"id":"00ba7a99","metadata":{"id":"00ba7a99"},"outputs":[],"source":["def get_cadence(all_peaks):\n","    all_cadence = []\n","    for peaks in all_peaks:\n","        # numbers of strides - 1 equal to steps since two consecutive stride form a step\n","        step_numbers = len(peaks[0])+len(peaks[1])-2\n","        # time = frame number of last stride - frame number of first stride\n","        time = ((max(peaks[0][-1], peaks[1][-1]) - min(peaks[0][0], peaks[1][0]))/24)/60\n","        cadence = round(step_numbers/time)\n","        all_cadence.append(cadence)\n","    return all_cadence\n","all_cadence_pd = get_cadence(all_peaks_pd)\n","all_cadence_normal = get_cadence(all_peaks_normal)"]},{"cell_type":"markdown","id":"601ed51a","metadata":{"id":"601ed51a"},"source":["### Mean speed"]},{"cell_type":"code","execution_count":null,"id":"81a96d24","metadata":{"id":"81a96d24"},"outputs":[],"source":["def get_mean_speed(all_peaks, ratioR, ratioL):\n","    all_mean_speed = []\n","    for i, peaks in enumerate(all_peaks):\n","        # Get walking time in second\n","        time = ((max(peaks[0][-1], peaks[1][-1]) - min(peaks[0][0], peaks[1][0]))/24)\n","        mean_ratio = (ratioR[i] + ratioL[i])/2\n","        mean_speed = mean_ratio/time\n","        all_mean_speed.append(mean_speed)\n","    return all_mean_speed\n","mean_speed_pd = get_mean_speed(all_peaks_pd, ratioR_pd, ratioL_pd)\n","mean_speed_normal = get_mean_speed(all_peaks_normal, ratioR_normal, ratioL_normal)"]},{"cell_type":"markdown","id":"bb7afc33","metadata":{"id":"bb7afc33"},"source":["### Turning features"]},{"cell_type":"code","execution_count":null,"id":"828dd6b4","metadata":{"id":"828dd6b4"},"outputs":[],"source":["def show_frame(cap):\n","    # Capture frames in the video\n","    success, frame = cap.read()\n","    if success:\n","        # describe the type of font\n","        # to be used.\n","        font = cv2.FONT_HERSHEY_SIMPLEX\n","        cv2.putText(frame, str(int(cap.get(cv2.CAP_PROP_POS_FRAMES))) + ' / ' \n","                    + str(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))), (0,20), \n","                    font, 0.6, (255,255,255), 2, cv2.LINE_AA)\n","\n","        # Display the resulting frame\n","        cv2.imshow('Turning determination', frame)\n","        return True\n","    else:\n","        return False\n","\n","# A small program to help to define the frame number of turning period\n","# press 'r' to record the current frame number\n","def video_determine_turning(video_path):\n","    \n","    cap = cv2.VideoCapture(video_path)\n","    fps = 24\n","    delay = int((1 / int(fps)) * 1000)\n","    pause = False\n","    turning_frame = []\n","    \n","    while True:\n","\n","        if not pause:\n","            success = show_frame(cap)\n","            if not success:\n","                break\n","            key = cv2.waitKey(delay)\n","        else:\n","            key = cv2.waitKey(-1)\n","        \n","        # next video\n","        if key == ord('q'):\n","            break\n","        elif key == ord('r'):\n","            turning_frame.append(cap.get(cv2.CAP_PROP_POS_FRAMES)-1)\n","            print(turning_frame)\n","            if len(turning_frame) >= 2:\n","                break\n","        # show next frame\n","        elif key == ord('x'):\n","            show_frame(cap)\n","        # show previous frame\n","        elif key == ord('z'):\n","            f = 2 if pause else 3\n","            cap.set(cv2.CAP_PROP_POS_FRAMES, cap.get(cv2.CAP_PROP_POS_FRAMES) - f)\n","            show_frame(cap)\n","        # show previous 10 frames\n","        elif key == ord('c'):\n","            cap.set(cv2.CAP_PROP_POS_FRAMES, cap.get(cv2.CAP_PROP_POS_FRAMES) - 10)\n","            show_frame(cap)\n","        # show next 10 frames\n","        elif key == ord('v'):\n","            cap.set(cv2.CAP_PROP_POS_FRAMES, cap.get(cv2.CAP_PROP_POS_FRAMES) + 10)\n","            show_frame(cap)\n","        # pause video\n","        elif key == ord(' '):\n","            pause = not pause\n","        # quit program\n","        elif key == ord('w'):\n","            cap.release()\n","            cv2.destroyAllWindows()\n","            raise Exception\n","    \n","    cap.release()\n","    cv2.destroyAllWindows()\n","    return turning_frame"]},{"cell_type":"code","execution_count":null,"id":"c3bcd76c","metadata":{"id":"c3bcd76c"},"outputs":[],"source":["def extract_video_name(video_path):\n","    return '_'.join(video_path.split('\\\\')[-1].split('.')[0].split('_')[1:])\n","\n","def define_turning(videos_path, csv_file_path):\n","    # read csv file that stored frame numbers of turning period\n","    if os.path.exists(csv_file_path):\n","        df = pd.read_csv(csv_file_path)\n","        # Only define turning for the video that not in csv file\n","        videos_path = [video_path for video_path in videos_path if extract_video_name(video_path) not in df['video_name'].values]\n","    else:\n","        df = pd.DataFrame(columns=['video_name', 'start', 'end'])\n","    \n","    for video_path in videos_path:\n","        try:\n","            turning_frame = video_determine_turning(video_path)\n","            turning_frame.insert(0, extract_video_name(video_path))\n","            # print selected frame number\n","            if len(turning_frame) > 1:\n","                print(turning_frame)\n","                print('')\n","            else:\n","                # If there is no turning period, insert nan value after video name\n","                turning_frame = turning_frame + [None, None]\n","            df.loc[len(df.index)] = turning_frame  \n","        except:\n","            break\n","    # Save csv file\n","    df.to_csv(csv_file_path, index=False)"]},{"cell_type":"code","execution_count":null,"id":"eac7cbf2","metadata":{"id":"eac7cbf2"},"outputs":[],"source":["csv_file_pd = 'turning_frames_pd.csv'\n","csv_file_normal = 'turning_frames_normal.csv'"]},{"cell_type":"code","execution_count":null,"id":"e94bb26b","metadata":{"id":"e94bb26b"},"outputs":[],"source":["define_turning(videos_path_pd, csv_file_pd)\n","define_turning(videos_path_normal, csv_file_normal)"]},{"cell_type":"code","execution_count":null,"id":"da04b645","metadata":{"id":"da04b645"},"outputs":[],"source":["# Read frame numbers of turning period from csv file\n","def read_turning(videos_path, csv_file_path):\n","    if os.path.exists(csv_file_path):\n","        df = pd.read_csv(csv_file_path)\n","        def replace_name(name):\n","            # Helper function to replace video name to the correspond index in keypoints data\n","            for i, video_path in enumerate(videos_path):\n","                if name in video_path:\n","                    return i\n","        df['video_name'] = df['video_name'].apply(lambda x: replace_name(x))\n","        print('Total number of videos with turning: ', (df.notnull().sum(axis=1) == len(df.columns)).sum())\n","        return df\n","    else:\n","        raise Exception('Cannot find the csv file.')"]},{"cell_type":"code","execution_count":null,"id":"0549e359","metadata":{"id":"0549e359","outputId":"5387b69c-dd4b-470d-ded2-a8179b2b1dfe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of videos with turning:  82\n","Total number of videos with turning:  11\n"]}],"source":["df_turning_pd = read_turning(videos_path_pd, csv_file_pd)\n","df_turning_normal = read_turning(videos_path_normal, csv_file_normal)"]},{"cell_type":"code","execution_count":null,"id":"93a4a2c3","metadata":{"id":"93a4a2c3"},"outputs":[],"source":["def compute_turning_duration(df):\n","    # Calculate duration in second for turning\n","    df['duration'] = (df['end'] - df['start'])/24\n","    return df['duration']\n","df_turning_duration_pd = compute_turning_duration(df_turning_pd)\n","df_turning_duration_normal = compute_turning_duration(df_turning_normal)"]},{"cell_type":"code","execution_count":null,"id":"bcec4f83","metadata":{"id":"bcec4f83","outputId":"262f3a0a-909a-43cc-fcf0-eb955625ed88"},"outputs":[{"data":{"text/plain":["0           NaN\n","1           NaN\n","2           NaN\n","3      9.291667\n","4           NaN\n","         ...   \n","287         NaN\n","288         NaN\n","289         NaN\n","290         NaN\n","291         NaN\n","Name: duration, Length: 292, dtype: float64"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Combine two dataframe for turning duration\n","df_turning_duration = df_turning_duration_pd.append(df_turning_duration_normal, ignore_index=True)\n","df_turning_duration"]},{"cell_type":"markdown","id":"5f436c9e","metadata":{"id":"5f436c9e"},"source":["### Turning steps"]},{"cell_type":"code","execution_count":null,"id":"2f3838e6","metadata":{"id":"2f3838e6"},"outputs":[],"source":["def turning_steps_segmentation(df, all_y):\n","    df['step_numbers'] = np.nan\n","    for index, row in df.iterrows():\n","        i = row['video_name']\n","        start = row['start']\n","        end = row['end']\n","        if not math.isnan(start):\n","            # use stride_segmentation function to segment strides in turning period\n","            peaks = stride_segmentation([all_y[int(i)][int(start):int(end)]])\n","            step_numbers = len(peaks[0][0])+len(peaks[0][1])\n","            df.loc[index, 'step_numbers'] = step_numbers\n","    return df['step_numbers']\n","\n","df_step_numbers_pd = turning_steps_segmentation(df_turning_pd, all_y_pd)\n","df_step_numbers_normal = turning_steps_segmentation(df_turning_normal, all_y_normal)"]},{"cell_type":"code","execution_count":null,"id":"9d45e4e8","metadata":{"id":"9d45e4e8","outputId":"55bf5cfe-a81f-4d90-f39f-fddf1174fcb3"},"outputs":[{"data":{"text/plain":["0       NaN\n","1       NaN\n","2       NaN\n","3      14.0\n","4       NaN\n","       ... \n","287     NaN\n","288     NaN\n","289     NaN\n","290     NaN\n","291     NaN\n","Name: step_numbers, Length: 292, dtype: float64"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["df_step_numbers = df_step_numbers_pd.append(df_step_numbers_normal, ignore_index=True)\n","df_step_numbers"]},{"cell_type":"code","execution_count":null,"id":"e9269c12","metadata":{"scrolled":true,"id":"e9269c12","outputId":"9ff3f2ef-fd42-4baf-8ea3-e57d10f33055"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ratioR</th>\n","      <th>ratioL</th>\n","      <th>cadence</th>\n","      <th>mean_speed</th>\n","      <th>turning_duration</th>\n","      <th>turning_steps</th>\n","      <th>parkinson</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.028705</td>\n","      <td>0.028705</td>\n","      <td>90</td>\n","      <td>0.001587</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.079651</td>\n","      <td>0.079651</td>\n","      <td>86</td>\n","      <td>0.006309</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.142220</td>\n","      <td>0.142220</td>\n","      <td>83</td>\n","      <td>0.009326</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.186680</td>\n","      <td>0.186680</td>\n","      <td>84</td>\n","      <td>0.006188</td>\n","      <td>9.291667</td>\n","      <td>14.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.092608</td>\n","      <td>0.092608</td>\n","      <td>84</td>\n","      <td>0.008082</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>287</th>\n","      <td>0.146164</td>\n","      <td>0.146164</td>\n","      <td>73</td>\n","      <td>0.017898</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>288</th>\n","      <td>0.148651</td>\n","      <td>0.148651</td>\n","      <td>77</td>\n","      <td>0.019181</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>289</th>\n","      <td>0.504445</td>\n","      <td>0.504445</td>\n","      <td>92</td>\n","      <td>0.069981</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>290</th>\n","      <td>0.645283</td>\n","      <td>0.645283</td>\n","      <td>79</td>\n","      <td>0.071040</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>291</th>\n","      <td>0.884937</td>\n","      <td>0.884937</td>\n","      <td>95</td>\n","      <td>0.117340</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>292 rows Ã— 7 columns</p>\n","</div>"],"text/plain":["       ratioR    ratioL  cadence  mean_speed  turning_duration  turning_steps  \\\n","0    0.028705  0.028705       90    0.001587               NaN            NaN   \n","1    0.079651  0.079651       86    0.006309               NaN            NaN   \n","2    0.142220  0.142220       83    0.009326               NaN            NaN   \n","3    0.186680  0.186680       84    0.006188          9.291667           14.0   \n","4    0.092608  0.092608       84    0.008082               NaN            NaN   \n","..        ...       ...      ...         ...               ...            ...   \n","287  0.146164  0.146164       73    0.017898               NaN            NaN   \n","288  0.148651  0.148651       77    0.019181               NaN            NaN   \n","289  0.504445  0.504445       92    0.069981               NaN            NaN   \n","290  0.645283  0.645283       79    0.071040               NaN            NaN   \n","291  0.884937  0.884937       95    0.117340               NaN            NaN   \n","\n","     parkinson  \n","0            1  \n","1            1  \n","2            1  \n","3            1  \n","4            1  \n","..         ...  \n","287          0  \n","288          0  \n","289          0  \n","290          0  \n","291          0  \n","\n","[292 rows x 7 columns]"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Create label\n","label = [1]*len(ratioR_pd) + [0]*len(ratioR_normal)\n","# Create dataframe\n","df = pd.DataFrame(\n","    {'ratioR': np.concatenate((ratioR_pd, ratioR_normal)),\n","     'ratioL': np.concatenate((ratioL_pd, ratioL_normal)),\n","     'cadence': all_cadence_pd + all_cadence_normal,\n","     'mean_speed': mean_speed_pd + mean_speed_normal,\n","     'turning_duration': df_turning_duration,\n","     'turning_steps': df_step_numbers,\n","     'parkinson': label\n","    })\n","df"]},{"cell_type":"code","execution_count":null,"id":"02359ade","metadata":{"id":"02359ade"},"outputs":[],"source":["# Save dataframe to csv file\n","df.to_csv('dataset.csv', mode='a', index=False, header=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}